{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e464268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('C:/Users/Derya/Downloads/ISEAR.csv')\n",
    "\n",
    "data = data.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8eea932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shame</td>\n",
       "      <td>When I realized that I was directing the feeli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMOTION                                               TEXT\n",
       "0     fear  Every time I imagine that someone I love or I ...\n",
       "1    anger  When I had been obviously unjustly treated and...\n",
       "2  sadness  When I think about the short time that we live...\n",
       "3  disgust  At a gathering I found myself involuntarily si...\n",
       "4    shame  When I realized that I was directing the feeli..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns =['EMOTION', 'TEXT']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cfd03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "import xgboost\n",
    "from sklearn import decomposition, ensemble\n",
    "import pandas, numpy, textblob, string\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d77aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join(a.lower() for a in a.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "374d65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join(a.replace('[^\\w\\s]','') for a in a.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9813f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b49eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join(a for a in a.split() if a not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62fc168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TEXT'] = data['TEXT'].apply(lambda a: str(TextBlob(a).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b154ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()\n",
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join([st.stem(word) for word in a.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a411d202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>everi time imagin someon love could contact se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>obvious unjustli treat possibl elucid this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>think short time live relat period life think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>gather found involuntarili sit next two peopl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>realiz direct feel discont partner way tri put...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMOTION                                               TEXT\n",
       "0        2  everi time imagin someon love could contact se...\n",
       "1        0        obvious unjustli treat possibl elucid this.\n",
       "2        6  think short time live relat period life think ...\n",
       "3        1  gather found involuntarili sit next two peopl ...\n",
       "4        7  realiz direct feel discont partner way tri put..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac188af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "object = preprocessing.LabelEncoder()\n",
    "data['EMOTION'] = object.fit_transform(data['EMOTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93d22ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1091\n",
       "6    1082\n",
       "0    1079\n",
       "2    1076\n",
       "7    1071\n",
       "1    1066\n",
       "3    1049\n",
       "4       1\n",
       "Name: EMOTION, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EMOTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2538c48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Xtrain, Xtest, Ytrain, Ytest \u001b[38;5;241m=\u001b[39m model_selection\u001b[38;5;241m.\u001b[39mtrain_test_split(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEXT\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMOTION\u001b[39m\u001b[38;5;124m'\u001b[39m],stratify\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMOTION\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2583\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2579\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2581\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2583\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1689\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \n\u001b[0;32m   1661\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2078\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2076\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2078\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2079\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2080\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2082\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2083\u001b[0m     )\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   2086\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2087\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2089\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = model_selection.train_test_split(data['TEXT'], data['EMOTION'],stratify= data['EMOTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(data['TEXT'])\n",
    "cv_xtrain = cv.transform(Xtrain)\n",
    "cv_xtest = cv.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9796a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer()\n",
    "tv.fit(data['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_xtrain = tv.transform(Xtrain)\n",
    "tv_xtest = tv.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed269840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(model_initializer, independent_variables_training, target, independent_variable_test):\n",
    "    model_initializer.fit(independent_variables_training, target)\n",
    " # predict\n",
    "    modelPred=classifier_model.predict(independent_variable_test)\n",
    "    return metrics.accuracy_score(modelPred, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877597bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build(naive_bayes.MultinomialNB(), cv_xtrain, Ytrain, cv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build(naive_bayes.MultinomialNB(), tv_xtrain, Ytrain, tv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build(linear_model.LogisticRegression(), cv_xtrain, Ytrain, cv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b857b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build(linear_model.LogisticRegression(), tv_xtrain, Ytrain, tv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84aecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build(svm.SVC(), cv_xtrain, Ytrain, cv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb74984",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build(svm.SVC(), tv_xtrain, Ytrain, tv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build(ensemble.RandomForestClassifier(), cv_xtrain, Ytrain,cv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0cb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = build(ensemble.RandomForestClassifier(), tv_xtrain, Ytrain, tv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression().fit(tv_xtrain, Ytrain)\n",
    "val_predictions = classifier.predict(tv_xtest)\n",
    "# Precision , Recall , F1 - score , Support\n",
    "y_true, y_pred = Ytest, val_predictions\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chart_studio.plotly as py\n",
    "# import plotly as ply\n",
    "# import cufflinks as cf\n",
    "# from plotly.graph_objs import *\n",
    "# from plotly.offline import *\n",
    "\n",
    "# init_notebook_mode(connected=True)\n",
    "# cf.set_config_file(offline=True, world_readable=True, theme='white')\n",
    "# Sentiment_df = pd.DataFrame(twt.Sentiment_label.value_counts().reset_index())\n",
    "# Sentiment_df.columns = ['Sentiment', 'Count']\n",
    "# Sentiment_df = pd.DataFrame(Sentiment_df)\n",
    "# Sentiment_df['Percentage'] = 100 * Sentiment_df['Count']/ Sentiment_df['Count'].sum()\n",
    "# Sentiment_Max = Sentiment_df.iloc[0,0] \n",
    "# Sentiment_percent = str(round(Sentiment_df.iloc[0,2],2))\n",
    "# fig1 = Sentiment_df.iplot(kind='pie',labels='Sentiment',values='Count',textinfo='label+percent', title= 'Sentiment Analysis', world_readable=True, asFigure=True)\n",
    "# ply.offline.plot(fig1,filename=\"Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bebe00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chart_studio.plotly as py\n",
    "# import plotly as ply\n",
    "# import cufflinks as cf\n",
    "# from plotly.graph_objs import *\n",
    "# from plotly.offline import *\n",
    "# init_notebook_mode(connected=True)\n",
    "# cf.set_config_file(offline=True, world_readable=True, theme='white')\n",
    "# Emotion_df = pd.DataFrame(twt.Emotion.value_counts().reset_index())\n",
    "# Emotion_df.columns = ['Emotion', 'Count']\n",
    "# Emotion_df = pd.DataFrame (Emotion_df)\n",
    "# Emotion_df['Percentage'] = 100 * Emotion_df['Count']/ Emotion_df['Count'].sum()\n",
    "# Emotion_Max = Emotion_df.iloc[0,0]\n",
    "# Emotion_percent = str(round(Emotion_df.iloc[0,2],2))\n",
    "# fig = Emotion_df.iplot(kind='pie', labels = 'Emotion', values = 'Count',pull= .2, hole=.2 , colorscale = 'reds', textposition='outside', \n",
    "# colors=['red','green','purple','orange','blue','yellow','pink'], textinfo='label+percent', title= 'Emotion Analysis', world_readable=True, \n",
    "# asFigure=True)\n",
    "# ply.offline.plot(fig,filename=\"Emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cfca6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "# Result = pd.crosstab(twt.Emotion, twt.Sentiment_label)\n",
    "# plt = Result.plot.bar(stacked=True,sort_columns = True)\n",
    "# plt.legend(title='Sentiment_label')\n",
    "# plt.figure.savefig('Emotion_Sentiment_stacked.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "676e812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from email.mime.text import MIMEText\n",
    "# from email.mime.multipart import MIMEMultipart\n",
    "# import os\n",
    "# from email.mime.application import MIMEApplication\n",
    "# from email import encoders\n",
    "# import smtplib\n",
    "# def generate_email():\n",
    "#      dir_path = \"Add PATH\"\n",
    "#      files = [\"Add files\"]\n",
    "#      # Add concerned address (you can add multiple address also) and \n",
    "#     Password\n",
    "#      company_dict = ['xyz@gmail.com']\n",
    "#      password = \"Password\"\n",
    "#      for value in company_dict:\n",
    "#      # Add From email address\n",
    "#      From_address = 'From email id'\n",
    "#      To_address = value\n",
    "#     text = MIMEMultipart()\n",
    "#     text['From'] = \"xxxx\"\n",
    "#     text['To'] = To_address\n",
    "#     text['Subject'] = \"Emotion Detection and Sentiment Analysis Report\"\n",
    "#     body = \" Hai \\n Greetings of the day,\\n We would like to inform \n",
    "#     you that the data is more about, \\n Emotion - \"+Emotion_Max+\" \n",
    "#     (\"+Emotion_percent+\" %).\\n Sentiment - \" +Sentiment_Max+\" \n",
    "#     (\"+Sentiment_percent+\" %).\\n\\n For the details please go through \n",
    "#     the attachments bellow. \\n\\n\\n\\n\\n Thank You.\"\n",
    "#     text.attach(MIMEText(body, 'plain'))\n",
    "#     for k in files: # add files to the message\n",
    "#     file_location = os.path.join(dir_location, k)\n",
    "#     attachment = MIMEApplication(open(file_location, \"rb\").read(), \n",
    "#     _subtype=\"txt\")\n",
    "#     attachment.add_header('Content-Disposition',obj, filename=k)\n",
    "#     text.attach(attachment)\n",
    "#     smtp = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "#     smtp.login(From_address, password)\n",
    "#     text1 = text.as_string()\n",
    "#     smtp.sendmail(From_address, To_address, text1)\n",
    "#     smtp.quit()\n",
    "#     return 'Successfully Sent..!'\n",
    "# #Calling the function to send reports\n",
    "# generate_email ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d8a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
